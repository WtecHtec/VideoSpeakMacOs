//
//  ContentView.swift
//  CaptureText
//
//  Created by shenruqi on 10/13/24.
//

import SwiftUI
import AVKit
import Vision

import AVFoundation
import Speech

import ImageIO
import UniformTypeIdentifiers
import Security 

struct ContentView: View {
    @State private var videoURL: URL?
    @State private var player: AVPlayer?
    @State private var isAnalyzing = false
    @State private var framesWithText: [FrameWithText] = []
    @State private var frames: [FrameWithText] = []
    @State private var audioTranscriptions: [AudioTranscription] = []
    @State private var progress: Float = 0
    
    @State private var selectedFrame: FrameWithText?
    @State private var isShowingPreview = false
 
    @State private var selectedTab = 0
    @State private var currentTime: CMTime = .zero
    @State private var isSelected = false
    
    @State private var downLoadError = false
    
    @ObservedObject var audioFileModel: AudioFileModel = AudioFileModel()
    
    // ÂÆö‰πâÁΩëÊ†ºÂ∏ÉÂ±Ä
    let columns: [GridItem] = Array(repeating: .init(.flexible()), count: 4)
    
    private let VideoWidth: CGFloat  = 192 * 2
    private let VideoHeight: CGFloat = 108 * 2
   
    @State private var selectedIndices: [UUID] = []
    
    @State private var isCanvasViewPresented = false
    
    @State private var searchText = ""
    
    @State private var downLoadUrl = ""
    
    @State private var  aiContents: [ContentItem] = []
    // ËÆ°ÁÆóÂ±ûÊÄß
    var filteredFrames: [FrameWithText] {
        if searchText.isEmpty {
            return framesWithText
        } else {
            return framesWithText.filter { $0.text.lowercased().contains(searchText.lowercased()) }
        }
    }
    
    
    var body: some View {
        HStack {
            VStack {
                VStack {
//                    HStack() {
//                        if let player = player {
//                            VideoPlayer(player: player)
//                                .frame(width: VideoWidth, height: VideoHeight)
//                        }
//                    }.frame(width: 480)
          
                    
                    HStack() {
                        if let player = player, !isSelected {
                            VideoPlayerView(player: $player, recognizedTexts: $frames, currentTime: $currentTime )
                                .frame(width: VideoWidth, height: VideoHeight)
                                .cornerRadius(10)
                                .overlay(
                                    RoundedRectangle(cornerRadius: 10)
                                        .stroke(Color.gray, lineWidth: 1)
                                ).onChange(of: player){}
                        } else {
                            RoundedRectangle(cornerRadius: 10)
                                .fill(Color.black.opacity(0.1))
                                .frame(width: VideoWidth, height: VideoHeight)
                                .overlay(
                                    Text( isSelected ? "ËßÜÈ¢ëÂä†ËΩΩ‰∏≠" :"Êú™ÈÄâÊã©ËßÜÈ¢ë")
                                        .foregroundColor(.gray)
                                )
                        }
                    }.frame(width: VideoWidth)
                    
                }
                HStack {
                    TextField("ËßÜÈ¢ëURL", text: $downLoadUrl)
                        .textFieldStyle(RoundedBorderTextFieldStyle())
                        .frame(width: 200)
                    Button("Ëß£ÊûêURLËßÜÈ¢ë") {
//                        YouGetExecutor.download(url: downLoadUrl, outputPath: "/Users/shenruqi/Downloads") { success, output, error in
//                            if success {
//                                print("‰∏ãËΩΩÊàêÂäüÔºÅËæìÂá∫Ôºö\n\(output)")
//                            } else {
//                                print("‰∏ãËΩΩÂ§±Ë¥•„ÄÇÈîôËØØÔºö\n\(error)")
//                            }
//                        }
                        
//                        YouGetExecutor.postDowdLoader(url: downLoadUrl) { status, output in
//                            if status {
//                                print("‰∏ãËΩΩÊàêÂäüÔºÅËæìÂá∫Ôºö\n\(output)")
//                            } else {
//                                print("‰∏ãËΩΩÂ§±Ë¥•„ÄÇÈîôËØØÔºö\n\(output)")
//                            }
//                        }
                        
                        isSelected = true
                        YouGetDownloader.postDowdLoader(url: downLoadUrl) { status, output in
                            if status  && !output.isEmpty {
                                print("‰∏ãËΩΩÊàêÂäüÔºÅËæìÂá∫Ôºö\n\(output)")
                                let url = URL(fileURLWithPath: output)
                                changeVideoFile(url: url)
                              
                            } else {
                                print("‰∏ãËΩΩÂ§±Ë¥•„ÄÇÈîôËØØÔºö\n\(output)")
                                isSelected = false
                                downLoadError = true
                            }
                        }
//                        YouGetExecutor.shell("you-get -i \(downLoadUrl)")
                        
                    }
                    
                    Button("‰∏ä‰º†ËßÜÈ¢ë") {
                        // ÂÆûÁé∞ËßÜÈ¢ëÈÄâÊã©ÈÄªËæë
                        selectVideo()
                    }
                }
                Spacer()
            }.frame(minWidth: 400)
            
//            List(framesWithText) { frame in
//                FrameView(frame: frame)
//                    .contentShape(Rectangle())
//                    .onTapGesture {
//                        // ÂÆûÁé∞Ë∑≥ËΩ¨Âà∞ÊåáÂÆöÂ∏ßÈÄªËæë
//                        seekToFrame(frame: frame)
////                        selectedFrame = frame
////                        isShowingPreview = true
//                    }
//                    .contextMenu {
//                        Button("ÂØºÂá∫ÂõæÁâá") {
//                            // ÂÆûÁé∞ÂØºÂá∫ÂõæÁâáÈÄªËæë
//                            exportImage(frame: frame)
//                        }
//                    }
//            }
            
            TabView(selection: $selectedTab) {
                VStack {
                ScrollView {
                    LazyVGrid(columns: columns, spacing: 20) {
                        //                         ForEach(framesWithText) { frame in
                        //                             FrameView(frame: frame, selectionIndex: nil)
                        //                                 .onTapGesture {
                        //                                     seekToFrame(frame: frame)
                        //                                 }
                        //                                 .contextMenu {
                        //                                     Button("ÂØºÂá∫ÂõæÁâá") {
                        //                                         // ÂÆûÁé∞ÂØºÂá∫ÂõæÁâáÈÄªËæë
                        //                                         exportImage(frame: frame)
                        //                                     }
                        //                                 }
                        //                         }
                        
                        
                        
                        ForEach(Array(filteredFrames.enumerated()), id: \.element.id) { index, frame  in
                            FrameView(frame: frame, selectionIndex: selectionIndex(for: frame.id))
                                .onTapGesture {
                                    //                                     seekToFrame(frame: frame)
                                    toggleSelection(of: frame.id)
                                }
                                .contextMenu {
                                    Button("ÂØºÂá∫ÂõæÁâá") {
                                        // ÂÆûÁé∞ÂØºÂá∫ÂõæÁâáÈÄªËæë
                                        ImageTool.exportImage(frame: frame)
                                    }
                                }
                        }
                        
                        
                    }
                    .frame(minWidth: 500)
                    .padding()
                    
                    
                    
                    
                }
                HStack {
                    SearchBar(text: $searchText)
                    
                    Button("ÊãºÊé•") {
                        isCanvasViewPresented = true
                    }
                    .disabled(selectedIndices.isEmpty)
                    
                     Button("Á´ãÂç≥AIÁîüÊàê ") {
                         
//                         if let jsonData = try? JSONEncoder().encode(aiContents),
//                            let jsonString = String(data: jsonData, encoding: .utf8) {
//                             print("JSON Â≠óÁ¨¶‰∏≤: \(aiContents.count)")
//                             YouGetDownloader.postAi(content: jsonString) {  status, data in
//                                 if status {
//                                     print("")
//                                 }
//                             }
//                         }
                         print("self.audioTranscriptions.isEmpty---", self.audioTranscriptions.isEmpty)
                         if !self.audioTranscriptions.isEmpty {
                             var content = ""
                             self.audioTranscriptions.forEach { audioTranscription in
                                 content = content + "\n" + audioTranscription.text
                             }
                              YouGetDownloader.postAi(content: content) {  status, data in
                                  if status {
                                      print("")
                                  }
                              }

                         }
                     }
                     .disabled(self.audioTranscriptions.isEmpty)
                    
//                    Button("Á´ãÂç≥ÁîüÊàêGIF") {
//                        saveImagesToGif(getSelectedImages(), loopCount: 0, frameDuration: 0.5)
//                    }
//                    .disabled(selectedIndices.isEmpty)
                    
                }.padding()
            }
                 .tabItem {
                     Image(systemName: "text.bubble")
                     Text("ÁîªÈù¢ÊñáÊú¨")
                 }
                 .tag(0)
                
                
//                ScrollView {
//                    LazyVGrid(columns: columns, spacing: 20) {
//                        ForEach(frames) { frame in
//                            FrameView(frame: frame, selectionIndex: nil)
//                                .onTapGesture {
//                                    seekToFrame(frame: frame)
//                                }
//                                .contextMenu {
//                                    Button("ÂØºÂá∫ÂõæÁâá") {
//                                        // ÂÆûÁé∞ÂØºÂá∫ÂõæÁâáÈÄªËæë
//                                        ImageTool.exportImage(frame: frame)
//                                    }
//                                }
//                        }
//                    }
//                    .padding()
//                }
//                 .tabItem {
//                       Image(systemName: "text.bubble")
//                       Text("ÁîªÈù¢ÂØπË±°")
//                   }
//                .tag(1)
                
                VStack {
                    
                    List(audioTranscriptions) { transcription in
                        AudioTranscriptionView(transcription: transcription)
                    }
                    .scrollContentBackground(.hidden) // ÈöêËóèÈªòËÆ§ËÉåÊôØ
                    .listStyle(PlainListStyle()) // ‰ΩøÁî®Êó†Ê†∑ÂºèÁöÑÂàóË°®
                    .edgesIgnoringSafeArea(.all)
                    
                    HStack {
                        if audioFileModel.exportInProgress {
                           ProgressView("ÂØºÂá∫‰∏≠...")
                       }

                        if audioFileModel.exportCompleted {
                           Text("ÂØºÂá∫ÊàêÂäü üéâ")
                               .foregroundColor(.green)
                       }

                        if let error = audioFileModel.exportError {
                           Text("ÂØºÂá∫Â§±Ë¥•: \(error)")
                               .foregroundColor(.red)
                       }
                        Spacer()
                        Button("ÂØºÂá∫Èü≥È¢ëÊñá‰ª∂") {
                            if let videoURL = self.videoURL {
                                audioFileModel.exportAudioFile(inVideoUrl: videoURL)
                            }
                        }
                        .disabled(audioFileModel.exportInProgress || self.videoURL == nil)
                    }
                    
                }
                 .tabItem {
                     Image(systemName: "waveform")
                     Text("Èü≥È¢ëÊñáÊú¨")
                 }
                 .tag(2)
                
            }
        }
        .padding()
        .frame(minWidth: 1000)
        .overlay(
            ToastView(message: "Ëß£ÊûêËßÜÈ¢ëURLÈîôËØØ", isShowing: $downLoadError)
                .padding()
        )
        .sheet(isPresented: $isCanvasViewPresented) {
            CanvasView(frameWithTexts: getSelectedImages())
        }.onAppear() {
   
        }
        
    }
    
    // ÂÖ∂‰ªñËæÖÂä©ÊñπÊ≥ï...
    
    private func getSelectedImages() -> [FrameWithText] {
        var selectedImages: [FrameWithText] = []
        selectedIndices.forEach { id in
            if let frame = framesWithText.first(where: { frameWithText in
                frameWithText.id == id
            }) {
                selectedImages.append(frame)
            }
        }
        return selectedImages
    }
    
    private func selectionIndex(for id: UUID) -> Int? {
          selectedIndices.firstIndex(of: id).map { $0 + 1 }
      }
    
    private func toggleSelection(of id: UUID) {
        if let existingIndex = selectedIndices.firstIndex(of: id) {
            selectedIndices.remove(at: existingIndex)
            // ÈáçÊñ∞ËÆ°ÁÆóÁ¥¢Âºï
            for i in existingIndex..<selectedIndices.count {
                selectedIndices[i] = selectedIndices[i]
            }
        } else {
            selectedIndices.append(id)
        }
    }
    
    
    // ÈÄâÊã©ËßÜÈ¢ë
    private func selectVideo() {
        let panel = NSOpenPanel()
        panel.allowsMultipleSelection = false
        panel.canChooseDirectories = false
        panel.canChooseFiles = true
        panel.allowedContentTypes = [.movie]
        
        panel.beginSheetModal(for: NSApp.keyWindow!) { response in
            if response == .OK, let url = panel.url {
                changeVideoFile(url: url)
                // Ê∑ªÂä†Êó∂Èó¥ËßÇÂØüÂô®
                self.player?.addPeriodicTimeObserver(forInterval: CMTime(seconds: 0.1, preferredTimescale: 600), queue: .main) { time in
                      self.currentTime = time
                  }
            }
        }
    }
    
    //
    private func changeVideoFile(url: URL) {
        isSelected = true
        self.videoURL = url
        self.player = AVPlayer(url: url)
        self.frames = []
        self.framesWithText = []
        self.audioTranscriptions = []
        self.selectedIndices = []
        DispatchQueue.main.async {
            isSelected = false
        }
        
       
        // Â§ÑÁêÜËßÜÈ¢ë
        DispatchQueue.global(qos: .userInitiated).async {
            
            if let url = videoURL {
                // Â≠óÂπï
                TranscribeAudio.transcribeAudio(from: url) { transcriptions in
                    DispatchQueue.main.async {
                        self.audioTranscriptions = TranscribeAudio.mergeTranscriptions(transcriptions)
                    }
                }
            }
        }
        DispatchQueue.global(qos: .background).async {
            analyzeVideo()
        }
          
    
    }

    
    private func analyzeVideo() {
        guard let videoURL = videoURL else { return }
        framesWithText.removeAll()
        isAnalyzing = true
        progress = 0
        let asset = AVAsset(url: videoURL)
        let duration = asset.duration.seconds
        let generator = AVAssetImageGenerator(asset: asset)
        generator.appliesPreferredTrackTransform = true
        
        var framesWithTextIng: [FrameWithText] = []
        var direct: [String: Bool] = [String: Bool]()
        
        let fps: Float = 2500000
        // ÈÅçÂéÜÊó∂Èó¥Êà≥ ‰ºö‰∏¢Â§±‰∏Ä‰∫õ
//        DispatchQueue.global(qos: .userInitiated).async {
//                 for time in stride(from: 0.0, to: duration, by: 1.0 / fps) {
//                     let cmTime = CMTime(seconds: time, preferredTimescale: 600)
//                     
//                     do {
//                         let cgImage = try generator.copyCGImage(at: cmTime, actualTime: nil)
//                         let nsImage = NSImage(cgImage: cgImage, size: NSSize(width: cgImage.width, height: cgImage.height))
//                         
//                         RecognizeText.recognizeTextInImage(image: CIImage(cgImage: cgImage)) { recognizedTexts in
//                                      if !recognizedTexts.isEmpty {
//                                          DispatchQueue.main.async {
//                                              let boundingBox: [CGRect] = []
//                                              recognizedTexts.forEach { recognizedText in
//                                                  if  direct[recognizedText.text] == false
//                                                        ||  direct[recognizedText.text] == nil {
//                                                      direct[recognizedText.text] = true
//                                                      framesWithTextIng.append(FrameWithText(
//                                                        image: nsImage,
//                                                        timestamp: cmTime,
//                                                        text: recognizedText.text,
//                                                        isWithText: true,
//                                                        textBounds: [recognizedText.boundingBox]
//                                                      ))
//                                                  }
//                                              }
////                                              self.frames.append(FrameWithText(
////                                                image: nsImage,
////                                                timestamp: cmTime,
////                                                text: "",
////                                                isWithText: false,
////                                                textBounds: boundingBox
////                                            ))
//                                          }
//                                      }
//                         }
//                         DispatchQueue.main.async {
//                             self.progress = Float(time / duration)
//                             self.framesWithText = framesWithTextIng
//                         }
//                     } catch {
//                         print("Error generating frame: \(error)")
//                     }
//                 }
//                 
//                 DispatchQueue.main.async {
//                     self.isAnalyzing = false
//                     self.progress = 1
//                     
//                 }
//             }
        
        
        //
        var index = 0
        RecognizeText.extractAllFramesByTime(from: videoURL, interval: 1) { cmTime, cgImage in
            let nsImage = NSImage(cgImage: cgImage, size: NSSize(width: cgImage.width, height: cgImage.height))
            RecognizeText.recognizeTextInImage(image: CIImage(cgImage: cgImage)) { recognizedTexts in
                if !recognizedTexts.isEmpty {
                    DispatchQueue.main.async {
                        let boundingBox: [CGRect] = []
                        recognizedTexts.forEach { recognizedText in
                            if  direct[recognizedText.text] == false
                                    ||  direct[recognizedText.text] == nil {
                                direct[recognizedText.text] = true
                                self.framesWithText.append(FrameWithText(
                                    image: nsImage,
                                    timestamp: cmTime,
                                    text: recognizedText.text,
                                    isWithText: true,
                                    textBounds: [recognizedText.boundingBox]
                                ))
                                self.aiContents.append(ContentItem(index: index,  text: recognizedText.text))
                                index = index + 1
                            }
                        }
                    }
                }
            }
        }
         DispatchQueue.main.async {
             self.isAnalyzing = false
             self.progress = 1
         }
        
    }
    

  
    
    
    
    private func seekToFrame(frame: FrameWithText) {
         player?.seek(to: frame.timestamp, toleranceBefore: .zero, toleranceAfter: .zero) { finished in
             if finished {
                 print("Â∑≤Ë∑≥ËΩ¨Âà∞Êó∂Èó¥Êà≥: \(frame.timestamp.seconds)")
                 // ÂèØÈÄâÔºöË∑≥ËΩ¨ÂêéËá™Âä®ÊöÇÂÅúËßÜÈ¢ë
                 self.player?.pause()
             }
         }
     }
    


    
 
    
}




#Preview {
    ContentView()
}
